{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Hot Encoding for Text to Vector Conversion in NLP\n",
    "\n",
    "One-Hot Encoding is a method used to convert categorical data into a numerical format that machine learning algorithms can understand. In the context of Natural Language Processing (NLP), we often need to convert words or phrases into numerical vectors.\n",
    "\n",
    "## What is One-Hot Encoding?\n",
    "\n",
    "In One-Hot Encoding, each word in the vocabulary is represented as a binary vector. The length of the vector is equal to the size of the vocabulary, and for each word, a `1` is placed in the position corresponding to that word, while all other positions are `0`.\n",
    "\n",
    "### Example Vocabulary\n",
    "\n",
    "Let's consider a simple vocabulary:\n",
    "- Vocabulary: `[\"apple\", \"banana\", \"orange\"]`\n",
    "\n",
    "The One-Hot Encodings for these words would be:\n",
    "- `apple`: `[1, 0, 0]`\n",
    "- `banana`: `[0, 1, 0]`\n",
    "- `orange`: `[0, 0, 1]`\n",
    "\n",
    "## Implementing One-Hot Encoding in Python\n",
    "\n",
    "We'll implement One-Hot Encoding using a small example.\n",
    "\n",
    "### Step 1: Create a Sample Text\n",
    "\n",
    "```python\n",
    "# Sample text\n",
    "text = \"apple banana apple orange\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"apple banana apple orange\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple', 'banana', 'orange'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a vocabulary from the text\n",
    "words = text.split()\n",
    "vocab = set(words)\n",
    "vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def one_hot_encode(word, vocab):\n",
    "    # Create a sorted list of vocabulary\n",
    "    vocab_list = sorted(vocab)\n",
    "    # Initialize a zero vector of length equal to vocabulary size\n",
    "    one_hot_vector = np.zeros(len(vocab_list))\n",
    "    # Set the position of the word to 1\n",
    "    index = vocab_list.index(word)\n",
    "    one_hot_vector[index] = 1\n",
    "    return one_hot_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': array([1., 0., 0.]),\n",
       " 'banana': array([0., 1., 0.]),\n",
       " 'orange': array([0., 0., 1.])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode each word in the sample text\n",
    "one_hot_encodings = {word: one_hot_encode(word, vocab) for word in words}\n",
    "one_hot_encodings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple: [1. 0. 0.]\n",
      "banana: [0. 1. 0.]\n",
      "orange: [0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Display the One-Hot Encodings\n",
    "for word, encoding in one_hot_encodings.items():\n",
    "    print(f\"{word}: {encoding}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disadvantages of One-Hot Encoding\n",
    "While One-Hot Encoding has its advantages, it also comes with several drawbacks:\n",
    "\n",
    "   High Dimensionality: The size of the one-hot encoded vectors increases with the vocabulary size. This can lead to a very sparse matrix, making computations inefficient.\n",
    "\n",
    "   No Semantic Meaning: One-Hot Encoding does not capture the relationships between words. For example, \"apple\" and \"banana\" are treated as completely unrelated even though they are both fruits.\n",
    "\n",
    "   Inability to Handle Unseen Words: If a new word appears that was not present in the training set, it cannot be represented in the one-hot encoded format without updating the vocabulary.\n",
    "\n",
    "   Memory Inefficiency: The sparse nature of the resulting matrices can lead to high memory usage, especially for large vocabularies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "kiwi: [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "grape: [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "banana: [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Larger vocabulary example\n",
    "large_vocab = [\"apple\", \"banana\", \"orange\", \"grape\", \"kiwi\", \"mango\", \"pineapple\", \"strawberry\", \"blueberry\"]\n",
    "text_large = \"apple kiwi grape banana\"\n",
    "words_large = text_large.split()\n",
    "\n",
    "one_hot_encodings_large = {word: one_hot_encode(word, large_vocab) for word in words_large}\n",
    "for word, encoding in one_hot_encodings_large.items():\n",
    "    print(f\"{word}: {encoding}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
